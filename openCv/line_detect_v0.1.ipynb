{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pdf2image import convert_from_path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defing the file path\n",
    "path = r'data\\sample.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert pdf to image\n",
    "def pdf_to_images(pdf_path):\n",
    "    return convert_from_path(pdf_path)\n",
    "\n",
    "# Calling the function to convert PDF to image\n",
    "images = pdf_to_images(path)\n",
    "\n",
    "# converting the image to numpy array\n",
    "image_np = np.array(images[0])\n",
    "# converting teh image to a gray image\n",
    "image_gray = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuction to display or save the image\n",
    "def display_image(sample_image, image_resize=False, image_name=r'sample_image.png'):\n",
    "    \"\"\"\n",
    "    This function is used to save or display the image\n",
    "    i/p: image, image_name \n",
    "    o/p: key board entry \"q\" to close the window\n",
    "         key board entry \"s\" to save the image\n",
    "    \"\"\"\n",
    "    # resize image\n",
    "    if image_resize == True:\n",
    "        sample_image = cv2.resize(sample_image, (1500, 1000))\n",
    "    else:\n",
    "        sample_image = sample_image\n",
    "\n",
    "    # Default image save path\n",
    "    path = r'data/gray_image/'\n",
    "    image_path = path + image_name\n",
    "    \n",
    "    cv2.imshow(\"converted image\",sample_image)\n",
    "\n",
    "    k = cv2.waitKey(0)\n",
    "\n",
    "    if k == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()\n",
    "    elif k == ord(\"s\"):\n",
    "        cv2.imwrite(image_path,sample_image)\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calling image display function\n",
    "# display_image(image_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contours Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Countor Detection \n",
    "# ret, thresh = cv2.threshold(img1, 127, 255, cv2.THRESH_BINARY)\n",
    "# contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# countor_img = cv2.drawContours(img1, contours, -1, (0, 0, 255), 3)\n",
    "\n",
    "# display_image(countor_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverting the gray image to have a better clarity on edge detection\n",
    "inverted_gray = cv2.bitwise_not(image_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # display_image(image_gray, True)\n",
    "# display_image(inverted_gray, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel_sharpening = np.array([[1,1], \n",
    "#                               [1,1]])\n",
    "\n",
    "# sharpened = cv2.filter2D(inverted_gray, -1, kernel_sharpening)\n",
    "\n",
    "# display_image(sharpened, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adap_edages = cv2.adaptiveThreshold(\n",
    "#     src = inverted_gray,\n",
    "#     maxValue = 255,\n",
    "#     adaptiveMethod = cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "#     thresholdType = cv2.THRESH_BINARY_INV,\n",
    "#     blockSize = 3,\n",
    "#     C = 5\n",
    "# )\n",
    "\n",
    "# display_image(adap_edages, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.adaptiveThreshold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(image=inverted_gray, threshold1=50, threshold2=800, \n",
    "                  apertureSize=3, L2gradient =False\n",
    "                  )\n",
    "\n",
    "# display_image(edges, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line Detection using HoughLines Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_image1 = image_gray.copy()\n",
    "# test_image2 = image_gray.copy()\n",
    "\n",
    "test_image1 = cv2.cvtColor(image_gray, cv2.COLOR_GRAY2BGR).copy()\n",
    "test_image2 = cv2.cvtColor(image_gray, cv2.COLOR_GRAY2BGR).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = cv2.HoughLines(inverted_gray, 1, np.pi/180, 200)\n",
    "    \n",
    "# if lines is not None:\n",
    "#     for line in lines:\n",
    "#         rho, theta = line[0]\n",
    "#         a = np.cos(theta)\n",
    "#         b = np.sin(theta)\n",
    "#         x0 = a * rho\n",
    "#         y0 = b * rho\n",
    "#         x1 = int(x0 + 1000 * (-b))\n",
    "#         y1 = int(y0 + 1000 * (a))\n",
    "#         x2 = int(x0 - 1000 * (-b))\n",
    "#         y2 = int(y0 - 1000 * (a))\n",
    "#         cv2.line(test_image1, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "# # Display the result\n",
    "# # resized_img = cv2.resize(test_image1, (1500, 1000))\n",
    "# # displaying the image\n",
    "# display_image(test_image1, True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'data\\gray_image\\input_line_1.png')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# i_gray = cv2.bitwise_not(gray)\n",
    "\n",
    "# Use morphological operations to emphasize thick lines\n",
    "# kernel = np.ones((5, 5), np.uint8)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "dilated = cv2.dilate(gray, kernel, iterations=1)\n",
    "eroded = cv2.erode(dilated, kernel, iterations=1)\n",
    "\n",
    "# Use the Canny edge detector\n",
    "edges = cv2.Canny(eroded, 50, 150, apertureSize=3)\n",
    "\n",
    "# Apply Hough Line Transform\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = cv2.HoughLinesP(inverted_gray, rho=1, theta=np.pi/180, threshold=100, minLineLength=1000, maxLineGap=10)\n",
    "\n",
    "if lines is not None:\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "# Display the result\n",
    "# resized_img1 = cv2.resize(test_image2, (1500, 1000))\n",
    "# displaying the image\n",
    "display_image(img, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouse Call Back "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "selected_line = None\n",
    "lines = None\n",
    "gray_bgr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_line(point, line):\n",
    "    rho, theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    return abs((point[0] - x0) * b - (point[1] - y0) * a) / np.sqrt(a**2 + b**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global selected_line, gray_bgr, lines\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        min_distance = float('inf')\n",
    "        for line in lines:\n",
    "            dist = distance_to_line((x, y), line)\n",
    "            if dist < min_distance:\n",
    "                min_distance = dist\n",
    "                selected_line = line\n",
    "\n",
    "        # Draw the selected line on the gray_bgr image\n",
    "        if selected_line is not None:\n",
    "            rho, theta = selected_line[0]\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            x1 = int(x0 + 1000 * (-b))\n",
    "            y1 = int(y0 + 1000 * (a))\n",
    "            x2 = int(x0 - 1000 * (-b))\n",
    "            y2 = int(y0 - 1000 * (a))\n",
    "            cv2.line(gray_bgr, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Highlight in green\n",
    "\n",
    "        # Refresh the displayed image\n",
    "        cv2.imshow('Select Line', gray_bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_dark_lines(image_path):\n",
    "    global gray_bgr, lines\n",
    "\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Convert the grayscale image back to BGR for colored line drawing\n",
    "    gray_bgr = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Invert the grayscale image to detect dark lines on a light background\n",
    "    inverted_gray = cv2.bitwise_not(gray)\n",
    "    \n",
    "    # Use the Canny edge detector\n",
    "    edges = cv2.Canny(inverted_gray, 50, 150, apertureSize=3)\n",
    "    \n",
    "    # Use the Hough Line Transform to detect lines\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi/180, 200)\n",
    "\n",
    "    cv2.namedWindow('Select Line')\n",
    "    cv2.setMouseCallback('Select Line', mouse_callback)\n",
    "    cv2.imshow('Select Line', gray_bgr)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Display the image with the selected line highlighted\n",
    "    if selected_line is not None:\n",
    "        display_image = gray_bgr.copy()\n",
    "        rho, theta = selected_line[0]\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        x1 = int(x0 + 1000 * (-b))\n",
    "        y1 = int(y0 + 1000 * (a))\n",
    "        x2 = int(x0 - 1000 * (-b))\n",
    "        y2 = int(y0 - 1000 * (a))\n",
    "        cv2.line(display_image, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Highlight in green\n",
    "\n",
    "        cv2.imshow('Selected Line', display_image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function\n",
    "image_path = \"data\\gray_image\\input_line_1.png\"\n",
    "detect_dark_lines(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
