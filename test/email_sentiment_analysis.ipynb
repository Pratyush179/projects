{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import dtale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10362, 9)\n"
     ]
    }
   ],
   "source": [
    "file_path = r'data\\email_3rd_june.parquet'\n",
    "df = pd.read_parquet(file_path)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = dtale.show(df)\n",
    "# d.open_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>from_email</th>\n",
       "      <th>to_email</th>\n",
       "      <th>cc_email</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>date_ist</th>\n",
       "      <th>time_ist</th>\n",
       "      <th>projectid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6d30273a-6d16-4c9a-b207-31261df388ba</td>\n",
       "      <td>a.cao@forell.com</td>\n",
       "      <td>samiranm@pinnacleinfotech.com</td>\n",
       "      <td>csutradhar@pinnaclecad.com, a.lin@forell.com</td>\n",
       "      <td>RE: 23-044 Drafting</td>\n",
       "      <td>Hi Sam,\\n\\nI've uploaded more markups here:\\nh...</td>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>05:13:05</td>\n",
       "      <td>76461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6b7a51f9-201f-43fa-adc2-f23203ee00d5</td>\n",
       "      <td>a.cao@forell.com</td>\n",
       "      <td>samiranm@pinnacleinfotech.com</td>\n",
       "      <td>csutradhar@pinnaclecad.com, a.lin@forell.com</td>\n",
       "      <td>RE: 23-043 Drafting</td>\n",
       "      <td>Sam,\\n\\nI've uploaded more markups here:\\nhttp...</td>\n",
       "      <td>2024-05-18</td>\n",
       "      <td>03:34:35</td>\n",
       "      <td>76461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id        from_email  \\\n",
       "0  6d30273a-6d16-4c9a-b207-31261df388ba  a.cao@forell.com   \n",
       "1  6b7a51f9-201f-43fa-adc2-f23203ee00d5  a.cao@forell.com   \n",
       "\n",
       "                        to_email  \\\n",
       "0  samiranm@pinnacleinfotech.com   \n",
       "1  samiranm@pinnacleinfotech.com   \n",
       "\n",
       "                                       cc_email              subject  \\\n",
       "0  csutradhar@pinnaclecad.com, a.lin@forell.com  RE: 23-044 Drafting   \n",
       "1  csutradhar@pinnaclecad.com, a.lin@forell.com  RE: 23-043 Drafting   \n",
       "\n",
       "                                                body    date_ist  time_ist  \\\n",
       "0  Hi Sam,\\n\\nI've uploaded more markups here:\\nh...  2024-05-16  05:13:05   \n",
       "1  Sam,\\n\\nI've uploaded more markups here:\\nhttp...  2024-05-18  03:34:35   \n",
       "\n",
       "   projectid  \n",
       "0      76461  \n",
       "1      76461  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_disclaimer_text(body):\n",
    "    \"\"\"\n",
    "    Remove disclaimer and classification notices from the email body.\n",
    "\n",
    "    Args:\n",
    "        body (str): The body of the email.\n",
    "        \n",
    "    Returns:\n",
    "        str: The email body without disclaimer and classification notices.\n",
    "    \"\"\"\n",
    "    disclaimer_pattern = [\n",
    "        r\"\\*This e-mail has been classified as.*\",\n",
    "        r\".*classification notice.*\",\n",
    "        r\"From:\\s.*Sent:\\s.*To:\\s.*\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in disclaimer_pattern:\n",
    "        body = re.sub(pattern, '', body, flags=re.DOTALL)\n",
    "    \n",
    "    return body\n",
    "\n",
    "def extract_recent_email(email_body):\n",
    "    \"\"\"\n",
    "    Extract the most recent part of an email thread above the signature or prior email content.\n",
    "\n",
    "    Args:\n",
    "        email_body (str): The body of the email.\n",
    "        \n",
    "    Returns:\n",
    "        str: The most recent part text.\n",
    "    \"\"\"\n",
    "    # Use BeautifulSoup to handle HTML email bodies.\n",
    "    soup = BeautifulSoup(email_body, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    lines = text.splitlines()\n",
    "\n",
    "    # Regex patterns for detecting common signature lines and previous messages\n",
    "    signature_patterns = [\n",
    "        re.compile(r'^(-{2,}|_{2,})'),  # Signatures, like \"-----Original Message-----\" or \"__\"\n",
    "        re.compile(r'^\\s*(Sent from my [\\w\\s]+|Sent with [\\w\\s]+)$', re.IGNORECASE), # Mobile signatures\n",
    "        re.compile(r'^On \\d{4}/[0-1]\\d/[0-3]\\d,.*'),  # Replies, like \"On 2021/12/01, ... wrote:\"\n",
    "        re.compile(r'^\\s*From:\\s*.*', re.IGNORECASE), # From header\n",
    "        re.compile(r'^\\s*Sent:\\s*.*', re.IGNORECASE), # Sent header\n",
    "        re.compile(r'^To:\\s*.*', re.IGNORECASE),      # To header\n",
    "        re.compile(r'^Subject:\\s*.*', re.IGNORECASE), # Subject header\n",
    "    ]\n",
    "\n",
    "    # Find the position of signature or previous message markers\n",
    "    for i, line in enumerate(lines):\n",
    "        for pattern in signature_patterns:\n",
    "            if pattern.match(line):\n",
    "                return \"\\n\".join(lines[:i]).strip()  # Return everything before the signature marker\n",
    "\n",
    "    return \"\\n\".join(lines).strip()\n",
    "\n",
    "def extract_text_above_signature(body, from_email):\n",
    "    \"\"\"\n",
    "    Extract text above the signature in the email body.\n",
    "\n",
    "    Args:\n",
    "        body (str): The body of the email.\n",
    "        from_email (str): The sender's email address.\n",
    "        \n",
    "    Returns:\n",
    "        str: The extracted text above signature patterns.\n",
    "    \"\"\"\n",
    "    username = from_email.split('@')[0]  # Extract the username\n",
    "    signature_patterns = [\n",
    "        r\"\\nfrom:\\s\", r\"\\nsent:\\s\", r\"\\nto:\\s\", r\"\\ncc:\\s\", r\"\\nsubject:\\s\",\n",
    "        r\"\\nregards,\\s\", r\"\\nbest,\\s\", r\"\\nthanks,\\s\", r\"\\nsincerely,\\s\", r\"\\ncheers,\\s\",\n",
    "        re.escape(username.lower())\n",
    "    ]\n",
    "    \n",
    "    body_lower = body.lower()\n",
    "    signature_indices = []\n",
    "    \n",
    "    # Find all occurrences of the signature patterns\n",
    "    for pattern in signature_patterns:\n",
    "        matches = list(re.finditer(pattern, body_lower, re.MULTILINE))\n",
    "        signature_indices.extend([match.start() for match in matches])\n",
    "    \n",
    "    if signature_indices:\n",
    "        signature_index = min(signature_indices)\n",
    "        return body[:signature_index].strip()\n",
    "    return body\n",
    "\n",
    "def clean_email_body(body):\n",
    "    \"\"\"\n",
    "    Clean the email body by removing unwanted text based on various regex patterns.\n",
    "\n",
    "    Args:\n",
    "        body (str): The body of the email.\n",
    "    \n",
    "    Returns:\n",
    "        str: The cleaned email body.\n",
    "    \"\"\"\n",
    "    patterns = {\n",
    "        'urls': r'https?://\\S+|www\\.\\S+',  # URLs\n",
    "        'metadata': r'(?m)^(From|Sent|To|Cc|Bcc|Subject|Date): .*$',  # Email metadata\n",
    "        'greetings': r'(?i)^(Hi|Hello|Dear|Greetings|Hey)\\s+[^\\n]+',  # Greetings\n",
    "        'signatures': r'(?i)(Best regards|Kind regards|Regards|Cheers|Thank you|Thanks|Sincerely|Yours truly|Yours sincerely|Best|Warm regards|With regards)[^\\n]+',  # Signatures\n",
    "        'email_headers': r'---* Forwarded message ---*|---* Original message ---*|---* Reply Above This Line ---*',  # Email forwarding/reply headers\n",
    "        'email_addresses': r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',  # Email addresses\n",
    "        'non_ascii': r'[^\\x00-\\x7F]+',  # Non-ASCII characters\n",
    "        'extra_lines': r'\\n{2,}',  # Excessive newlines\n",
    "        'html_tags': r'<[^>]*>',  # HTML tags\n",
    "        'brackets_content': r'\\[.*?\\]|\\{.*?\\}|\\<.*?\\>',  # Content within brackets\n",
    "        'extra_whitespace': r'\\s{2,}',  # Excessive whitespace\n",
    "        'unsubscribe_links': r'Unsubscribe\\s+:.*|Click\\s+here.*unsubscribe',  # Unsubscribe links\n",
    "        'reply_lines': r'On\\s+.*wrote:',  # Lines indicating the start of a reply\n",
    "        'quoted_text': r'(?m)^\\>.*$',  # Lines starting with \">\"\n",
    "        'repeated_chars': r'(.)\\1{2,}',  # Repeated characters\n",
    "        'generic_signature_lines': r'(?i)(^Sent from my \\w+)|(--\\n.*)|(Confidentiality Notice.*)',  # Generic email signatures or legal disclaimers\n",
    "        'timestamps': r'\\d{1,2}:\\d{2}\\s*(AM|PM|am|pm)?',  # Time stamps\n",
    "        'dates': r'\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}',  # Dates\n",
    "        'signature_blocks': r'--\\s*\\n[\\s\\S]*',  # Signature blocks that start with -- followed by any text\n",
    "        'headers_and_footers': r'(?m)^\\s*-\\s*$\\n[\\s\\S]*?^\\s*-\\s*$',  # Headers and footers denoted by lines consisting of dashes\n",
    "        'mobile_numbers': r'\\b(\\+?(\\d{1,3})?[-. ]?)?((\\(\\d{1,4}\\))|\\d{1,4})[-. ]?\\d{1,4}[-. ]?\\d{1,9}\\b'  # Mobile numbers\n",
    "    }\n",
    "    \n",
    "    for key, pattern in patterns.items():\n",
    "        body = re.sub(pattern, ' ', body)\n",
    "    \n",
    "    # Remove excess whitespace\n",
    "    body = re.sub(r'\\s{2,}', ' ', body)\n",
    "    return body.strip()\n",
    "\n",
    "\n",
    "def extract_most_recent_email_part(email_body, from_email):\n",
    "    \"\"\"\n",
    "    Combine recent email extraction and signature pattern extraction for robust extraction.\n",
    "\n",
    "    Args:\n",
    "        email_body (str): The body of the email.\n",
    "        from_email (str): The sender's email address.\n",
    "        \n",
    "    Returns:\n",
    "        str: The extracted relevant part of the email above signatures and prior threads.\n",
    "    \"\"\"\n",
    "    # Remove disclaimer and notice sections\n",
    "    cleaned_body = remove_disclaimer_text(email_body)\n",
    "    \n",
    "    # Extract the most recent email section ignoring previous emails\n",
    "    recent_email_content = extract_recent_email(cleaned_body)\n",
    "    \n",
    "    # Extract text above signatures and replies\n",
    "    filtered_content_above_signature = extract_text_above_signature(recent_email_content, from_email)\n",
    "\n",
    "    # Clean the email body\n",
    "    cleaned_body = clean_email_body(filtered_content_above_signature)\n",
    "    \n",
    "    return filtered_content_above_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pis05408.PINNACLE\\AppData\\Local\\Temp\\ipykernel_12740\\449057951.py:33: MarkupResemblesLocatorWarning:\n",
      "\n",
      "The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply the extraction function\n",
    "df['clean_email'] = df.apply(lambda row: extract_most_recent_email_part(row['body'], row['from_email']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = dtale.show(test)\n",
    "# d.open_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "#### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Define the sentiment analysis pipeline using pretraned model \n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model = \"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to predict sentiment with text truncation\n",
    "def predict_sentiment_truncated(text, max_length=512):\n",
    "    truncated_text = text[:max_length]\n",
    "    result = sentiment_pipeline(truncated_text)\n",
    "    return result[0] if result else {'label': 'UNKNOWN', 'score': 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the sentiment prediction function\n",
    "df['sentiment_distilbert'] = df['clean_email'].apply(predict_sentiment_truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the sentiment label and score into separate columns\n",
    "df['transformer_label'] = df['sentiment_distilbert'].apply(lambda x: x['label'])\n",
    "# df['sentiment_distilbert_score'] = df['sentiment_distilbert'].apply(lambda x: x['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformer_label\n",
       "NEGATIVE    2153\n",
       "POSITIVE    1222\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['transformer_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = dtale.show(df)\n",
    "# d.open_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict sentiment using TextBlob\n",
    "def predict_sentiment_textblob(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentiment = blob.sentiment\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the sentiment analysis function\n",
    "df['sentiment_blob'] = df['clean_email'].apply(predict_sentiment_textblob)\n",
    "\n",
    "# Extract the sentiment label and score into separate columns\n",
    "df['blob_label'] = df['sentiment_blob'].apply(lambda x: 'POSITIVE' if x.polarity > 0 else ('NEGATIVE' if x.polarity < 0 else 'NEUTRAL'))\n",
    "# df['sentiment_blob_score'] = df['sentiment'].apply(lambda x: x.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blob_label\n",
       "POSITIVE    2021\n",
       "NEUTRAL      840\n",
       "NEGATIVE     514\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.blob_label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = dtale.show(df)\n",
    "# d.open_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\pis05408.PINNACLE\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the VADER lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict sentiment using VADER\n",
    "def predict_sentiment_nltk(text):\n",
    "    sentiment = analyzer.polarity_scores(text)\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the sentiment analysis function\n",
    "df['sentiment_NLTK'] = df['clean_email'].apply(predict_sentiment_nltk)\n",
    "\n",
    "# Extract the sentiment label and score into separate columns\n",
    "df['nltk_label'] = df['sentiment_NLTK'].apply(lambda x: 'POSITIVE' if x['compound'] >= 0.05 else ('NEGATIVE' if x['compound'] <= -0.05 else 'NEUTRAL'))\n",
    "df['sentiment_nltk_score'] = df['sentiment_NLTK'].apply(lambda x: x['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nltk_label\n",
      "POSITIVE    8483\n",
      "NEUTRAL     1238\n",
      "NEGATIVE     641\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['nltk_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dtale.show(df)\n",
    "d.open_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Suraj\\projects\\test\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning:\n",
      "\n",
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Suraj\\projects\\test\\env\\lib\\site-packages\\spacy\\util.py:837: UserWarning:\n",
      "\n",
      "[W095] Model 'en_core_web_sm' (3.7.1) was trained with spaCy v3.7 and may not be 100% compatible with the current version (3.3.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "\n"
     ]
    },
    {
     "ename": "RegistryError",
     "evalue": "[E892] Unknown function registry: 'vectors'.\n\nAvailable names: architectures, augmenters, batchers, callbacks, cli, datasets, displacy_colors, factories, initializers, languages, layers, lemmatizers, loggers, lookups, losses, misc, models, ops, optimizers, readers, schedules, scorers, tokenizers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRegistryError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the SpaCy model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Add the TextBlob component to the SpaCy pipeline\u001b[39;00m\n\u001b[0;32m      5\u001b[0m nlp\u001b[38;5;241m.\u001b[39madd_pipe(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspacytextblob\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Suraj\\projects\\test\\env\\lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     31\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     37\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     38\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Suraj\\projects\\test\\env\\lib\\site-packages\\spacy\\util.py:420\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_lang_class(name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblank:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))()\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_package(name):  \u001b[38;5;66;03m# installed as package\u001b[39;00m\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_package(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(name)\u001b[38;5;241m.\u001b[39mexists():  \u001b[38;5;66;03m# path to model data directory\u001b[39;00m\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Suraj\\projects\\test\\env\\lib\\site-packages\\spacy\\util.py:453\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03mname (str): The package name.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(name)\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Suraj\\projects\\test\\env\\lib\\site-packages\\en_core_web_sm\\__init__.py:10\u001b[0m, in \u001b[0;36mload\u001b[1;34m(**overrides)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moverrides):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_init_py(\u001b[38;5;18m__file__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moverrides)\n",
      "File \u001b[1;32mc:\\Suraj\\projects\\test\\env\\lib\\site-packages\\spacy\\util.py:619\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[1;34m(init_file, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE052\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mdata_path))\n\u001b[1;32m--> 619\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Suraj\\projects\\test\\env\\lib\\site-packages\\spacy\\util.py:488\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[1;34m(model_path, meta, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    486\u001b[0m overrides \u001b[38;5;241m=\u001b[39m dict_to_dot(config)\n\u001b[0;32m    487\u001b[0m config \u001b[38;5;241m=\u001b[39m load_config(config_path, overrides\u001b[38;5;241m=\u001b[39moverrides)\n\u001b[1;32m--> 488\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nlp\u001b[38;5;241m.\u001b[39mfrom_disk(model_path, exclude\u001b[38;5;241m=\u001b[39mexclude, overrides\u001b[38;5;241m=\u001b[39moverrides)\n",
      "File \u001b[1;32mc:\\Suraj\\projects\\test\\env\\lib\\site-packages\\spacy\\util.py:528\u001b[0m, in \u001b[0;36mload_model_from_config\u001b[1;34m(config, meta, vocab, disable, exclude, auto_fill, validate)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;66;03m# This will automatically handle all codes registered via the languages\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;66;03m# registry, including custom subclasses provided via entry points\u001b[39;00m\n\u001b[0;32m    527\u001b[0m lang_cls \u001b[38;5;241m=\u001b[39m get_lang_class(nlp_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 528\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mlang_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_fill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nlp\n",
      "File \u001b[1;32mc:\\Suraj\\projects\\test\\env\\lib\\site-packages\\spacy\\language.py:1755\u001b[0m, in \u001b[0;36mLanguage.from_config\u001b[1;34m(cls, config, vocab, disable, exclude, meta, auto_fill, validate)\u001b[0m\n\u001b[0;32m   1753\u001b[0m     filled[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretraining\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m orig_pretraining\n\u001b[0;32m   1754\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretraining\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m orig_pretraining\n\u001b[1;32m-> 1755\u001b[0m resolved_nlp \u001b[38;5;241m=\u001b[39m \u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1756\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilled\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnlp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConfigSchemaNlp\u001b[49m\n\u001b[0;32m   1757\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1758\u001b[0m create_tokenizer \u001b[38;5;241m=\u001b[39m resolved_nlp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1759\u001b[0m before_creation \u001b[38;5;241m=\u001b[39m resolved_nlp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbefore_creation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Suraj\\projects\\test\\env\\lib\\site-packages\\thinc\\config.py:746\u001b[0m, in \u001b[0;36mregistry.resolve\u001b[1;34m(cls, config, schema, overrides, validate)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresolve\u001b[39m(\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    744\u001b[0m     validate: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    745\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m--> 746\u001b[0m     resolved, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resolved\n",
      "File \u001b[1;32mc:\\Suraj\\projects\\test\\env\\lib\\site-packages\\thinc\\config.py:795\u001b[0m, in \u001b[0;36mregistry._make\u001b[1;34m(cls, config, schema, overrides, resolve, validate)\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interpolated:\n\u001b[0;32m    794\u001b[0m     config \u001b[38;5;241m=\u001b[39m Config(orig_config)\u001b[38;5;241m.\u001b[39minterpolate()\n\u001b[1;32m--> 795\u001b[0m filled, _, resolved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fill\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolve\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    798\u001b[0m filled \u001b[38;5;241m=\u001b[39m Config(filled, section_order\u001b[38;5;241m=\u001b[39msection_order)\n\u001b[0;32m    799\u001b[0m \u001b[38;5;66;03m# Check that overrides didn't include invalid properties not in config\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Suraj\\projects\\test\\env\\lib\\site-packages\\thinc\\config.py:849\u001b[0m, in \u001b[0;36mregistry._fill\u001b[1;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[0;32m    847\u001b[0m     field \u001b[38;5;241m=\u001b[39m schema\u001b[38;5;241m.\u001b[39m__fields__[key]\n\u001b[0;32m    848\u001b[0m     schema\u001b[38;5;241m.\u001b[39m__fields__[key] \u001b[38;5;241m=\u001b[39m copy_model_field(field, Any)\n\u001b[1;32m--> 849\u001b[0m promise_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_promise_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m filled[key], validation[v_key], final[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_fill(\n\u001b[0;32m    851\u001b[0m     value,\n\u001b[0;32m    852\u001b[0m     promise_schema,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    856\u001b[0m     overrides\u001b[38;5;241m=\u001b[39moverrides,\n\u001b[0;32m    857\u001b[0m )\n\u001b[0;32m    858\u001b[0m reg_name, func_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_constructor(final[key])\n",
      "File \u001b[1;32mc:\\Suraj\\projects\\test\\env\\lib\\site-packages\\thinc\\config.py:1040\u001b[0m, in \u001b[0;36mregistry.make_promise_schema\u001b[1;34m(cls, obj, resolve)\u001b[0m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resolve \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mhas(reg_name, func_name):\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m EmptySchema\n\u001b[1;32m-> 1040\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreg_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;66;03m# Read the argument annotations and defaults from the function signature\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m id_keys \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Suraj\\projects\\test\\env\\lib\\site-packages\\spacy\\util.py:129\u001b[0m, in \u001b[0;36mregistry.get\u001b[1;34m(cls, registry_name, func_name)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, registry_name):\n\u001b[0;32m    128\u001b[0m     names \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_registry_names()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RegistryError(Errors\u001b[38;5;241m.\u001b[39mE892\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mregistry_name, available\u001b[38;5;241m=\u001b[39mnames))\n\u001b[0;32m    130\u001b[0m reg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, registry_name)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mRegistryError\u001b[0m: [E892] Unknown function registry: 'vectors'.\n\nAvailable names: architectures, augmenters, batchers, callbacks, cli, datasets, displacy_colors, factories, initializers, languages, layers, lemmatizers, loggers, lookups, losses, misc, models, ops, optimizers, readers, schedules, scorers, tokenizers"
     ]
    }
   ],
   "source": [
    "# Load the SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add the TextBlob component to the SpaCy pipeline\n",
    "nlp.add_pipe(\"spacytextblob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict sentiment using SpaCy\n",
    "def predict_sentiment_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    sentiment = {\n",
    "        'label': 'POSITIVE' if doc._.polarity > 0 else ('NEGATIVE' if doc._.polarity < 0 else 'NEUTRAL'),\n",
    "        'score': doc._.polarity\n",
    "    }\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the sentiment analysis function\n",
    "df['sentiment_spacy'] = df['clean_email'].apply(predict_sentiment_spacy)\n",
    "\n",
    "# Extract the sentiment label and score into separate columns\n",
    "df['spacy_label'] = df['sentiment_spacy'].apply(lambda x: x['label'])\n",
    "#df['sentiment_spacy_score'] = df['sentiment_spacy'].apply(lambda x: x['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_spacy_label\n",
       "POSITIVE    2021\n",
       "NEUTRAL      840\n",
       "NEGATIVE     514\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['sentiment_spacy_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the data \n",
    "df.to_parquet('data/sentiment_data_output_3rdjun.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data for validation\n",
    "data = pd.read_parquet('data\\sentiment_data_output_3rdjun.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 21:27:24,175 - INFO     - Executing shutdown due to inactivity...\n",
      "2024-06-03 21:27:28,275 - INFO     - Executing shutdown...\n",
      "2024-06-03 21:27:28,281 - INFO     - Not running with the Werkzeug Server, exiting by searching gc for BaseWSGIServer\n"
     ]
    }
   ],
   "source": [
    "d = dtale.show(data)\n",
    "d.open_browser()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
