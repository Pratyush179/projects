{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import dtale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3375, 9)\n"
     ]
    }
   ],
   "source": [
    "file_path = r'data\\emailsentiment_2.parquet'\n",
    "df = pd.read_parquet(file_path)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = dtale.show(df)\n",
    "# d.open_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>from_email</th>\n",
       "      <th>to_email</th>\n",
       "      <th>cc_email</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>date_ist</th>\n",
       "      <th>time_ist</th>\n",
       "      <th>projectid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>af6c2697-de52-4bca-9454-bd9ec04286e8</td>\n",
       "      <td>aaron@constructionchannel.tv</td>\n",
       "      <td>anants@pinnacleinfotech.com</td>\n",
       "      <td>tanveer.singh@jpr.pinnaclecad.com, lsharma@pin...</td>\n",
       "      <td>Re: [EXTERNAL] Re: ABMS Hangar</td>\n",
       "      <td>Per our process, did you update Autodesk Const...</td>\n",
       "      <td>2024-04-24</td>\n",
       "      <td>21:55:04</td>\n",
       "      <td>77901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33feb1a9-3b8f-4d95-82ee-d5accabc96da</td>\n",
       "      <td>abraham.canlas@gcinc.com</td>\n",
       "      <td>dkataria@pinnacleinfotech.com</td>\n",
       "      <td>miguel.sapao@gcinc.com, sunilk@pinnacleinfotec...</td>\n",
       "      <td>RE: Tristar Vault 3D Model</td>\n",
       "      <td>Hi Deepak,\\r\\nLet me know if you received the ...</td>\n",
       "      <td>2024-04-18</td>\n",
       "      <td>05:43:17</td>\n",
       "      <td>75205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                    from_email  \\\n",
       "0  af6c2697-de52-4bca-9454-bd9ec04286e8  aaron@constructionchannel.tv   \n",
       "1  33feb1a9-3b8f-4d95-82ee-d5accabc96da      abraham.canlas@gcinc.com   \n",
       "\n",
       "                        to_email  \\\n",
       "0    anants@pinnacleinfotech.com   \n",
       "1  dkataria@pinnacleinfotech.com   \n",
       "\n",
       "                                            cc_email  \\\n",
       "0  tanveer.singh@jpr.pinnaclecad.com, lsharma@pin...   \n",
       "1  miguel.sapao@gcinc.com, sunilk@pinnacleinfotec...   \n",
       "\n",
       "                          subject  \\\n",
       "0  Re: [EXTERNAL] Re: ABMS Hangar   \n",
       "1      RE: Tristar Vault 3D Model   \n",
       "\n",
       "                                                body    date_ist  time_ist  \\\n",
       "0  Per our process, did you update Autodesk Const...  2024-04-24  21:55:04   \n",
       "1  Hi Deepak,\\r\\nLet me know if you received the ...  2024-04-18  05:43:17   \n",
       "\n",
       "   projectid  \n",
       "0      77901  \n",
       "1      75205  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_disclaimer_text(body):\n",
    "    \"\"\"\n",
    "    Remove disclaimer and classification notices from the email body.\n",
    "\n",
    "    Args:\n",
    "        body (str): The body of the email.\n",
    "        \n",
    "    Returns:\n",
    "        str: The email body without disclaimer and classification notices.\n",
    "    \"\"\"\n",
    "    disclaimer_pattern = [\n",
    "        r\"\\*This e-mail has been classified as.*\",\n",
    "        r\".*classification notice.*\",\n",
    "        r\"From:\\s.*Sent:\\s.*To:\\s.*\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in disclaimer_pattern:\n",
    "        body = re.sub(pattern, '', body, flags=re.DOTALL)\n",
    "    \n",
    "    return body\n",
    "\n",
    "def extract_recent_email(email_body):\n",
    "    \"\"\"\n",
    "    Extract the most recent part of an email thread above the signature or prior email content.\n",
    "\n",
    "    Args:\n",
    "        email_body (str): The body of the email.\n",
    "        \n",
    "    Returns:\n",
    "        str: The most recent part text.\n",
    "    \"\"\"\n",
    "    # Use BeautifulSoup to handle HTML email bodies.\n",
    "    soup = BeautifulSoup(email_body, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    lines = text.splitlines()\n",
    "\n",
    "    # Regex patterns for detecting common signature lines and previous messages\n",
    "    signature_patterns = [\n",
    "        re.compile(r'^(-{2,}|_{2,})'),  # Signatures, like \"-----Original Message-----\" or \"__\"\n",
    "        re.compile(r'^\\s*(Sent from my [\\w\\s]+|Sent with [\\w\\s]+)$', re.IGNORECASE), # Mobile signatures\n",
    "        re.compile(r'^On \\d{4}/[0-1]\\d/[0-3]\\d,.*'),  # Replies, like \"On 2021/12/01, ... wrote:\"\n",
    "        re.compile(r'^\\s*From:\\s*.*', re.IGNORECASE), # From header\n",
    "        re.compile(r'^\\s*Sent:\\s*.*', re.IGNORECASE), # Sent header\n",
    "        re.compile(r'^To:\\s*.*', re.IGNORECASE),      # To header\n",
    "        re.compile(r'^Subject:\\s*.*', re.IGNORECASE), # Subject header\n",
    "    ]\n",
    "\n",
    "    # Find the position of signature or previous message markers\n",
    "    for i, line in enumerate(lines):\n",
    "        for pattern in signature_patterns:\n",
    "            if pattern.match(line):\n",
    "                return \"\\n\".join(lines[:i]).strip()  # Return everything before the signature marker\n",
    "\n",
    "    return \"\\n\".join(lines).strip()\n",
    "\n",
    "def extract_text_above_signature(body, from_email):\n",
    "    \"\"\"\n",
    "    Extract text above the signature in the email body.\n",
    "\n",
    "    Args:\n",
    "        body (str): The body of the email.\n",
    "        from_email (str): The sender's email address.\n",
    "        \n",
    "    Returns:\n",
    "        str: The extracted text above signature patterns.\n",
    "    \"\"\"\n",
    "    username = from_email.split('@')[0]  # Extract the username\n",
    "    signature_patterns = [\n",
    "        r\"\\nfrom:\\s\", r\"\\nsent:\\s\", r\"\\nto:\\s\", r\"\\ncc:\\s\", r\"\\nsubject:\\s\",\n",
    "        r\"\\nregards,\\s\", r\"\\nbest,\\s\", r\"\\nthanks,\\s\", r\"\\nsincerely,\\s\", r\"\\ncheers,\\s\",\n",
    "        re.escape(username.lower())\n",
    "    ]\n",
    "    \n",
    "    body_lower = body.lower()\n",
    "    signature_indices = []\n",
    "    \n",
    "    # Find all occurrences of the signature patterns\n",
    "    for pattern in signature_patterns:\n",
    "        matches = list(re.finditer(pattern, body_lower, re.MULTILINE))\n",
    "        signature_indices.extend([match.start() for match in matches])\n",
    "    \n",
    "    if signature_indices:\n",
    "        signature_index = min(signature_indices)\n",
    "        return body[:signature_index].strip()\n",
    "    return body\n",
    "\n",
    "def clean_email_body(body):\n",
    "    \"\"\"\n",
    "    Clean the email body by removing unwanted text based on various regex patterns.\n",
    "\n",
    "    Args:\n",
    "        body (str): The body of the email.\n",
    "    \n",
    "    Returns:\n",
    "        str: The cleaned email body.\n",
    "    \"\"\"\n",
    "    patterns = {\n",
    "        'urls': r'https?://\\S+|www\\.\\S+',  # URLs\n",
    "        'metadata': r'(?m)^(From|Sent|To|Cc|Bcc|Subject|Date): .*$',  # Email metadata\n",
    "        'greetings': r'(?i)^(Hi|Hello|Dear|Greetings|Hey)\\s+[^\\n]+',  # Greetings\n",
    "        'signatures': r'(?i)(Best regards|Kind regards|Regards|Cheers|Thank you|Thanks|Sincerely|Yours truly|Yours sincerely|Best|Warm regards|With regards)[^\\n]+',  # Signatures\n",
    "        'email_headers': r'---* Forwarded message ---*|---* Original message ---*|---* Reply Above This Line ---*',  # Email forwarding/reply headers\n",
    "        'email_addresses': r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',  # Email addresses\n",
    "        'non_ascii': r'[^\\x00-\\x7F]+',  # Non-ASCII characters\n",
    "        'extra_lines': r'\\n{2,}',  # Excessive newlines\n",
    "        'html_tags': r'<[^>]*>',  # HTML tags\n",
    "        'brackets_content': r'\\[.*?\\]|\\{.*?\\}|\\<.*?\\>',  # Content within brackets\n",
    "        'extra_whitespace': r'\\s{2,}',  # Excessive whitespace\n",
    "        'unsubscribe_links': r'Unsubscribe\\s+:.*|Click\\s+here.*unsubscribe',  # Unsubscribe links\n",
    "        'reply_lines': r'On\\s+.*wrote:',  # Lines indicating the start of a reply\n",
    "        'quoted_text': r'(?m)^\\>.*$',  # Lines starting with \">\"\n",
    "        'repeated_chars': r'(.)\\1{2,}',  # Repeated characters\n",
    "        'generic_signature_lines': r'(?i)(^Sent from my \\w+)|(--\\n.*)|(Confidentiality Notice.*)',  # Generic email signatures or legal disclaimers\n",
    "        'timestamps': r'\\d{1,2}:\\d{2}\\s*(AM|PM|am|pm)?',  # Time stamps\n",
    "        'dates': r'\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}',  # Dates\n",
    "        'signature_blocks': r'--\\s*\\n[\\s\\S]*',  # Signature blocks that start with -- followed by any text\n",
    "        'headers_and_footers': r'(?m)^\\s*-\\s*$\\n[\\s\\S]*?^\\s*-\\s*$',  # Headers and footers denoted by lines consisting of dashes\n",
    "        'mobile_numbers': r'\\b(\\+?(\\d{1,3})?[-. ]?)?((\\(\\d{1,4}\\))|\\d{1,4})[-. ]?\\d{1,4}[-. ]?\\d{1,9}\\b'  # Mobile numbers\n",
    "    }\n",
    "    \n",
    "    for key, pattern in patterns.items():\n",
    "        body = re.sub(pattern, ' ', body)\n",
    "    \n",
    "    # Remove excess whitespace\n",
    "    body = re.sub(r'\\s{2,}', ' ', body)\n",
    "    return body.strip()\n",
    "\n",
    "\n",
    "def extract_most_recent_email_part(email_body, from_email):\n",
    "    \"\"\"\n",
    "    Combine recent email extraction and signature pattern extraction for robust extraction.\n",
    "\n",
    "    Args:\n",
    "        email_body (str): The body of the email.\n",
    "        from_email (str): The sender's email address.\n",
    "        \n",
    "    Returns:\n",
    "        str: The extracted relevant part of the email above signatures and prior threads.\n",
    "    \"\"\"\n",
    "    # Remove disclaimer and notice sections\n",
    "    cleaned_body = remove_disclaimer_text(email_body)\n",
    "    \n",
    "    # Extract the most recent email section ignoring previous emails\n",
    "    recent_email_content = extract_recent_email(cleaned_body)\n",
    "    \n",
    "    # Extract text above signatures and replies\n",
    "    filtered_content_above_signature = extract_text_above_signature(recent_email_content, from_email)\n",
    "\n",
    "    # Clean the email body\n",
    "    cleaned_body = clean_email_body(filtered_content_above_signature)\n",
    "    \n",
    "    return filtered_content_above_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pis05408.PINNACLE\\AppData\\Local\\Temp\\ipykernel_24332\\449057951.py:33: MarkupResemblesLocatorWarning:\n",
      "\n",
      "The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply the extraction function\n",
    "df['clean_email'] = df.apply(lambda row: extract_most_recent_email_part(row['body'], row['from_email']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = dtale.show(test)\n",
    "# d.open_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "#### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Define the sentiment analysis pipeline using pretraned model \n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model = \"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to predict sentiment with text truncation\n",
    "def predict_sentiment_truncated(text, max_length=512):\n",
    "    truncated_text = text[:max_length]\n",
    "    result = sentiment_pipeline(truncated_text)\n",
    "    return result[0] if result else {'label': 'UNKNOWN', 'score': 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the sentiment prediction function\n",
    "df['sentiment_distilbert'] = df['clean_email'].apply(predict_sentiment_truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the sentiment label and score into separate columns\n",
    "df['transformer_label'] = df['sentiment_distilbert'].apply(lambda x: x['label'])\n",
    "# df['sentiment_distilbert_score'] = df['sentiment_distilbert'].apply(lambda x: x['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformer_label\n",
       "NEGATIVE    2153\n",
       "POSITIVE    1222\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['transformer_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = dtale.show(df)\n",
    "# d.open_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict sentiment using TextBlob\n",
    "def predict_sentiment_textblob(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentiment = blob.sentiment\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the sentiment analysis function\n",
    "df['sentiment_blob'] = df['clean_email'].apply(predict_sentiment_textblob)\n",
    "\n",
    "# Extract the sentiment label and score into separate columns\n",
    "df['blob_label'] = df['sentiment_blob'].apply(lambda x: 'POSITIVE' if x.polarity > 0 else ('NEGATIVE' if x.polarity < 0 else 'NEUTRAL'))\n",
    "# df['sentiment_blob_score'] = df['sentiment'].apply(lambda x: x.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blob_label\n",
       "POSITIVE    2021\n",
       "NEUTRAL      840\n",
       "NEGATIVE     514\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.blob_label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = dtale.show(df)\n",
    "# d.open_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\pis05408.PINNACLE\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the VADER lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict sentiment using VADER\n",
    "def predict_sentiment_nltk(text):\n",
    "    sentiment = analyzer.polarity_scores(text)\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the sentiment analysis function\n",
    "df['sentiment_NLTK'] = df['clean_email'].apply(predict_sentiment_nltk)\n",
    "\n",
    "# Extract the sentiment label and score into separate columns\n",
    "df['nltk_label'] = df['sentiment_NLTK'].apply(lambda x: 'POSITIVE' if x['compound'] >= 0.05 else ('NEGATIVE' if x['compound'] <= -0.05 else 'NEUTRAL'))\n",
    "#df['sentiment_nltk_score'] = df['sentiment_NLTK'].apply(lambda x: x['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_nltk_label\n",
       "POSITIVE    4009\n",
       "NEUTRAL      564\n",
       "NEGATIVE     328\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['sentiment_nltk_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = dtale.show(df)\n",
    "# d.open_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x22d2e97cd60>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add the TextBlob component to the SpaCy pipeline\n",
    "nlp.add_pipe(\"spacytextblob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict sentiment using SpaCy\n",
    "def predict_sentiment_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    sentiment = {\n",
    "        'label': 'POSITIVE' if doc._.polarity > 0 else ('NEGATIVE' if doc._.polarity < 0 else 'NEUTRAL'),\n",
    "        'score': doc._.polarity\n",
    "    }\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the sentiment analysis function\n",
    "df['sentiment_spacy'] = df['clean_email'].apply(predict_sentiment_spacy)\n",
    "\n",
    "# Extract the sentiment label and score into separate columns\n",
    "df['spacy_label'] = df['sentiment_spacy'].apply(lambda x: x['label'])\n",
    "#df['sentiment_spacy_score'] = df['sentiment_spacy'].apply(lambda x: x['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_spacy_label\n",
       "POSITIVE    2021\n",
       "NEUTRAL      840\n",
       "NEGATIVE     514\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['sentiment_spacy_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Writing the data \n",
    "# df.to_parquet('data/sentiment_data_output.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reading the data for validation\n",
    "# data = pd.read_parquet('data\\sentiment_data_output.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = dtale.show(data)\n",
    "# d.open_browser()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
